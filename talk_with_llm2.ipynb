{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv \n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Completion Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llmModel = OpenAI() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chat Completion Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "chatModel = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prompt & Prompt templates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completion Model \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {curious} story about {topic}\"\n",
    ")\n",
    "\n",
    "llmModelPrompt = prompt_template.format(\n",
    "    curious = \"fascinating\",\n",
    "    topic = \"Humanoids\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(llmModelPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Once upon a time, in a distant galaxy, there was a planet called Zorion. This planet was inhabited by humanoids, a highly advanced species with remarkable abilities. They had the ability to shape-shift, control elements, and communicate telepathically.\n",
      "\n",
      "The humanoids lived in harmony with nature and each other, using their powers for the greater good. However, their peaceful existence was threatened when a group of ruthless invaders from a neighboring planet called Xerxes attacked Zorion.\n",
      "\n",
      "The Xerxesians were known for their greed and desire for power. They wanted to enslave the humanoids and steal their powers for themselves. The humanoids, with their advanced technology and abilities, put up a fierce fight, but were eventually outnumbered and forced to flee their planet.\n",
      "\n",
      "The humanoids managed to escape to a nearby planet, Earth, where they sought refuge and disguised themselves as humans. They blended in seamlessly, using their abilities only when necessary. They quickly adapted to human society and began to live among them, keeping their true identity a secret.\n",
      "\n",
      "As the centuries passed, the humanoids kept a watchful eye on Earth and its inhabitants, using their powers to protect and guide them from behind the scenes. They became known as the \"guardians of Earth\"\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Chat Completion model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Scientist specializing in Humanoids, I can offer some insights into how humanoids may evolve in the future. Evolution is a complex and multifaceted process that is influenced by a variety of factors, including environmental pressures, technological advancements, and societal changes.\n",
      "\n",
      "One possible direction for the evolution of humanoids is through the integration of advanced technologies. With the rapid development of robotics, artificial intelligence, and biotechnology, it is conceivable that humanoids could become more technologically sophisticated and capable. This could involve enhancements such as increased strength, agility, intelligence, and sensory capabilities.\n",
      "\n",
      "Additionally, as our understanding of genetics and bioengineering advances, it is possible that humanoids may undergo genetic modifications to enhance their physical and cognitive abilities. This could lead to the emergence of new humanoid species with unique characteristics designed for specific tasks or environments.\n",
      "\n",
      "Furthermore, changes in the environment, such as climate change or shifts in ecosystems, could drive adaptations in humanoids to better suit their changing surroundings. This could result in the development of new physiological features or behavioral traits that optimize their survival and reproduction in these altered conditions.\n",
      "\n",
      "Overall, the evolution of humanoids is likely to be a complex and dynamic process shaped by a combination of biological, technological, and environmental factors. It is important to note that predicting the exact trajectory of humanoid evolution is challenging and speculative, but considering these various factors can provide some insight into potential future developments.\n"
     ]
    }
   ],
   "source": [
    "# Zero Shot Prompting\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a {profession} expert on {topic}\"),\n",
    "        (\"human\", \"Hello, {profession} can you please answer a question\"),\n",
    "        (\"ai\", \"Sure!\"), \n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ] \n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession = \"Scientist\", \n",
    "    topic = \"Humanoids\", \n",
    "    user_input = \"How will humanoids evolve ?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages) \n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Prompting \n",
    "\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"hola!\"}, \n",
    "    {\"input\": \"bye!\", \"output\": \"adios!\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"), \n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt, \n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator\"),\n",
    "        few_shot_prompt, \n",
    "        (\"human\", \"{input}\") \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | chatModel\n",
    "\n",
    "response = chain.invoke({\"input\" : \"How are you ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Output Parsers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI \n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model = \"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate \n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_promt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_promt | llmModel | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = json_chain.invoke({\"question\": \"What is the biggest and largest country by land and population?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The biggest and largest country by land and population is China.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pydantic to define a custom output format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate \n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pydantic Object with the desired output format.\n",
    "class Joke(BaseModel):\n",
    "    setup : str = Field(description=\"question to set up a joke\")\n",
    "    punchline : str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parser referring the Pydantic Object\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Add the parser format instructions in the prompt defination.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\", \n",
    "    input_variables = [\"query\"], \n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a chain with the prompt and the parser \n",
    "chain = prompt | chatModel | parser\n",
    "\n",
    "chain.invoke({\"query\": \"Tell me a Joke\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
